{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building RAG Chatbots with LangChain\n",
    "(taken from [LangChain's documentation](https://github.com/pinecone-io/examples/blob/master/learn/generation/langchain/rag-chatbot.ipynb)\n",
    "\n",
    "\n",
    "In this example, we'll work on building an AI chatbot from start-to-finish. We will be using LangChain, OpenAI, and Pinecone vector DB, to build a chatbot capable of learning from the external world using Retrieval Augmented Generation (RAG).\n",
    "\n",
    "We will be using a dataset sourced from the Llama 2 ArXiv paper and other related papers to help our chatbot answer questions about the latest and greatest in the world of GenAI.\n",
    "\n",
    "By the end of the example we'll have a functioning chatbot and RAG pipeline that can hold a conversation and provide informative responses based on a knowledge base.\n",
    "\n",
    "## Before you begin\n",
    "You'll need to get an OpenAI API key and Pinecone API key.\n",
    "\n",
    "## Prerequisites\n",
    "Before we start building our chatbot, we need to install some Python libraries. Here's a brief overview of what each library does:\n",
    "\n",
    "**langchain**: This is a library for GenAI. We'll use it to chain together different language models and components for our chatbot.\n",
    "\n",
    "**openai**: This is the official OpenAI Python client. We'll use it to interact with the OpenAI API and generate responses for our chatbot.\n",
    "\n",
    "**datasets**: This library provides a vast array of datasets for machine learning. We'll use it to load our knowledge base for the chatbot.\n",
    "\n",
    "**pinecone-client**: This is the official Pinecone Python client. We'll use it to interact with the Pinecone API and store our chatbot's knowledge base in a vector database.\n",
    "\n",
    "You can install these libraries using pip like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU \\\n",
    "    langchain==0.0.292 \\\n",
    "    openai==0.28.0 \\\n",
    "    datasets==2.10.1 \\\n",
    "    pinecone-client==2.2.4 \\\n",
    "    tiktoken==0.5.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Chatbot (no RAG)\n",
    "We will be relying heavily on the LangChain library to bring together the different components needed for our chatbot. To begin, we'll create a simple chatbot without any retrieval augmentation. We do this by initializing a ChatOpenAI object. For this we do need an OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or \"YOUR_API_KEY\"\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    model='gpt-3.5-turbo'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chats with OpenAI's gpt-3.5-turbo and gpt-4 chat models are typically structured (in plain text) like this:\n",
    "```python\n",
    "System: You are a helpful assistant.\n",
    "\n",
    "User: Hi AI, how are you today?\n",
    "\n",
    "Assistant: I'm great thank you. How can I help you?\n",
    "\n",
    "User: I'd like to understand string theory.\n",
    "\n",
    "Assistant:\n",
    "```\n",
    "\n",
    "The final \"Assistant:\" without a response is what would prompt the model to continue the conversation. In the official OpenAI ChatCompletion endpoint these would be passed to the model in a format like:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi AI, how are you today?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm great thank you. How can I help you?\"}\n",
    "    {\"role\": \"user\", \"content\": \"I'd like to understand string theory.\"}\n",
    "]\n",
    "```\n",
    "In LangChain there is a slightly different format. We use three message objects like so:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format is very similar, we're just swapped the role of \"user\" for HumanMessage, and the role of \"assistant\" for AIMessage.\n",
    "\n",
    "We generate the next response from the AI by passing these messages to the ChatOpenAI object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure, I can help you with that. String theory is a theoretical framework in physics that attempts to explain the fundamental nature of particles and their interactions. It proposes that the fundamental building blocks of the universe are not point-like particles, but rather tiny, vibrating strings.\\n\\nIn string theory, these strings can vibrate in different ways, producing different particles with different properties. The vibrations of these strings determine the mass, charge, and other fundamental characteristics of particles.\\n\\nOne of the key ideas in string theory is that it requires extra dimensions beyond the three spatial dimensions (length, width, and height) that we are familiar with. These extra dimensions are compactified or curled up in tiny, microscopic sizes that are not directly observable in our everyday experience.\\n\\nString theory also suggests the existence of different types of strings, such as closed loops or open-ended strings. Closed strings form closed loops and give rise to particles that are force carriers, like photons and gravitons. Open strings have two endpoints and can give rise to particles that make up matter, such as electrons and quarks.\\n\\nOne of the major goals of string theory is to unify all the fundamental forces of nature, including gravity, electromagnetism, and the strong and weak nuclear forces. It offers a potential framework for reconciling quantum mechanics (which governs the behavior of particles at the smallest scales) with general relativity (which describes gravity on the largest scales).\\n\\nHowever, it's important to note that string theory is still a developing field and many aspects of it remain speculative. It is an active area of research, and scientists are working to refine and test the theory through mathematical calculations and experimental observations.\\n\\nI hope this gives you a general understanding of string theory. Let me know if you have any more specific questions!\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = chat(messages)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In response we get another AI message object. We can print it more clearly like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I can help you with that. String theory is a theoretical framework in physics that attempts to explain the fundamental nature of particles and their interactions. It proposes that the fundamental building blocks of the universe are not point-like particles, but rather tiny, vibrating strings.\n",
      "\n",
      "In string theory, these strings can vibrate in different ways, producing different particles with different properties. The vibrations of these strings determine the mass, charge, and other fundamental characteristics of particles.\n",
      "\n",
      "One of the key ideas in string theory is that it requires extra dimensions beyond the three spatial dimensions (length, width, and height) that we are familiar with. These extra dimensions are compactified or curled up in tiny, microscopic sizes that are not directly observable in our everyday experience.\n",
      "\n",
      "String theory also suggests the existence of different types of strings, such as closed loops or open-ended strings. Closed strings form closed loops and give rise to particles that are force carriers, like photons and gravitons. Open strings have two endpoints and can give rise to particles that make up matter, such as electrons and quarks.\n",
      "\n",
      "One of the major goals of string theory is to unify all the fundamental forces of nature, including gravity, electromagnetism, and the strong and weak nuclear forces. It offers a potential framework for reconciling quantum mechanics (which governs the behavior of particles at the smallest scales) with general relativity (which describes gravity on the largest scales).\n",
      "\n",
      "However, it's important to note that string theory is still a developing field and many aspects of it remain speculative. It is an active area of research, and scientists are working to refine and test the theory through mathematical calculations and experimental observations.\n",
      "\n",
      "I hope this gives you a general understanding of string theory. Let me know if you have any more specific questions!\n"
     ]
    }
   ],
   "source": [
    "print(res.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Because `res` is just another `AIMessage` object, we can append it to `messages`, add another `HumanMessage`, and generate the next response in the conversation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"Why do physicists believe it can produce a 'unified theory'?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to chat-gpt\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Hallucinations\n",
    "\n",
    "We have our chatbot, but as mentioned — the knowledge of LLMs can be limited. The reason for this is that LLMs learn all they know during training. An LLM essentially compresses the \"world\" as seen in the training data into the internal parameters of the model. We call this knowledge the *parametric knowledge* of the model.\n",
    "\n",
    "By default, LLMs have no access to the external world.\n",
    "\n",
    "The result of this is very clear when we ask LLMs about more recent information, like about the new (and very popular) Llama 2 LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"What is so special about Llama 2?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have any information on something called \"Llama 2.\" It's possible that you might be referring to something specific that I'm not aware of. Could you please provide more context or clarify your question so that I can better assist you?\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chatbot can no longer help us, it doesn't contain the information we need to answer the question. It was very clear from this answer that the LLM doesn't know the informaiton, but sometimes an LLM may respond like it does know the answer — and this can be very hard to detect.\n",
    "\n",
    "OpenAI have since adjusted the behavior for this particular example as we can see below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
